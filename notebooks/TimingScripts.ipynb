{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import corpora \n",
    "from gensim.models.ldamodel import LdaModel \n",
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from htrc_features import FeatureReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file = datapath(\"PrelimTopicModel2\")\n",
    "\n",
    "lda_model = LdaModel.load(temp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = glob.glob('../data/testfiles/*.bz2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sgoodwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sgoodwin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS \n",
    "\n",
    "ADD_PUNC = '”“’’–˙ˆ‘'\n",
    "STOPWORDS = {'d', 'c', 'e', 's', 'œ', 'dhs', 'hk', 'nagy', 'eology', 'ey', 'g', 'ing', 'tion', 'er', 'rst', 'vol', 'ed'} \n",
    "AUTHOR_NAMES = {'cruz', 'frederiks', 'nagy', 'snyder', 'nguyen', 'prior', 'cavanaugh', 'heyer', 'schmil', 'smith', 'groody', 'campese', 'izuzquiza', 'heimburger', 'myers', 'colwell', 'olofinjana', 'krabill', 'norton', 'theocharous', 'nacpil', 'nnamani', 'soares', 'thompson', 'zendher', 'ahn', 'haug', 'sarmiento', 'davidson', 'rowlands', 'strine', 'zink', 'jimenez'}\n",
    "STOPWORDS = STOPWORDS.union(AUTHOR_NAMES)\n",
    "STOPWORDS = STOPWORDS.union(ENGLISH_STOP_WORDS)\n",
    "PUNCDIG_TRANSLATOR = str.maketrans('', '', string.punctuation+string.digits+ADD_PUNC)\n",
    "\n",
    "def text_clean(text):\n",
    "    clean_list = []\n",
    "    words = nltk.word_tokenize(text)\n",
    "    for w in words:\n",
    "        if w not in STOPWORDS and len(w) > 2: # removing two character words\n",
    "            w = w.translate(PUNCDIG_TRANSLATOR)\n",
    "            if w != '':\n",
    "                clean_list.append(lemmatizer.lemmatize(w))\n",
    "    return clean_list\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def volume_parser(vol):\n",
    "    vol_list = []\n",
    "    for page in vol.pages():\n",
    "        df = page.tokenlist('body', case=False, pos=False)\n",
    "        dicty = df.to_dict()\n",
    "        count = dicty['count']\n",
    "        clean_list = []\n",
    "        for key in count.keys():\n",
    "            w = key[2]\n",
    "            if w not in STOPWORDS and len(w) > 2: # removing two character words\n",
    "                w = w.translate(PUNCDIG_TRANSLATOR)\n",
    "                if w != '':\n",
    "                    clean_list += [lemmatizer.lemmatize(w)] * count[key]\n",
    "                    # clean_list.append(lemmatizer.lemmatize(w) * count[key])\n",
    "        vol_list.append(clean_list)\n",
    "    return vol_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vol_gen(paths):\n",
    "    fr = FeatureReader(paths)\n",
    "    for vol in fr.volumes():\n",
    "        yield vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_generation = vol_gen(paths)\n",
    "vol = next(vol_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The 12-year Reich : a social history of Nazi Germany, 1933-1945 / Richard Grunberger.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_list = volume_parser(vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dict = Dictionary.load_from_text('./models/corpus_dictionary_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_list = [corpus_dict.doc2bow(text) for text in vol_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_corpus_with_model(other_corpus, lda_model):\n",
    "    pot_match = []\n",
    "    for doc_num, doc in enumerate(other_corpus):\n",
    "        vector = lda_model[doc]\n",
    "        # row = sorted(vector[0], key=lambda x: x[1], reverse=True)\n",
    "        row = vector[0]\n",
    "        topic_num, prop_topic = row[0]\n",
    "        if topic_num in (0, 1, 3, 5, 6, 11) and prop_topic > .04:\n",
    "            pot_match.append((doc_num, topic_num, prop_topic))\n",
    "    return pot_match\n",
    "\n",
    "    '''\n",
    "    sorted_list = sorted(pot_match, key=lambda x: x[-1], reverse=True)\n",
    "    return sorted_list\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_list = analyze_corpus_with_model(corpus_list, lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 6, 0.7523192)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sorted_list, key=lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(482, 6, 0.752285)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(sorted_list, key=lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "def wrapper(func, *args, **kwargs):\n",
    "    def wrapped():\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped = wrapper(max, sorted_list, key=lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.595497417999468"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(wrapped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_sort(lst):\n",
    "    return sorted(lst, key=lambda x: x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_sort = wrapper(list_sort, sorted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.28719097300018"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeit.timeit(wrapped_sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = lda_model[corpus_list[100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1, 0.25644043),\n",
       "  (5, 0.120921254),\n",
       "  (6, 0.0846427),\n",
       "  (10, 0.12059769),\n",
       "  (12, 0.25669894),\n",
       "  (21, 0.113198526)],\n",
       " [(5, [5]),\n",
       "  (11, [1, 6]),\n",
       "  (16, [1, 12, 21, 5]),\n",
       "  (22, [12, 5]),\n",
       "  (26, [10]),\n",
       "  (28, [1]),\n",
       "  (38, [21]),\n",
       "  (51, [1, 21, 5]),\n",
       "  (56, [12, 5, 21]),\n",
       "  (67, [10, 21, 5, 12, 6]),\n",
       "  (68, [12, 5]),\n",
       "  (76, [10, 12, 21]),\n",
       "  (79, [6]),\n",
       "  (89, [12, 21])],\n",
       " [(5, [(5, 0.9999911)]),\n",
       "  (11, [(1, 1.7476194), (6, 0.2523553)]),\n",
       "  (16, [(1, 0.42299974), (5, 0.018924559), (12, 0.3835322), (21, 0.17453243)]),\n",
       "  (22, [(5, 0.27588192), (12, 0.7240828)]),\n",
       "  (26, [(10, 0.9999945)]),\n",
       "  (28, [(1, 0.9903614)]),\n",
       "  (38, [(21, 0.99999326)]),\n",
       "  (51, [(1, 0.9021005), (5, 0.019916726), (21, 0.07797805)]),\n",
       "  (56, [(5, 0.11033381), (12, 0.8119678), (21, 0.07768639)]),\n",
       "  (67,\n",
       "   [(5, 0.18650338),\n",
       "    (6, 0.062213406),\n",
       "    (10, 0.36962354),\n",
       "    (12, 0.09858051),\n",
       "    (21, 0.28307194)]),\n",
       "  (68, [(5, 0.2804311), (12, 0.7195571)]),\n",
       "  (76, [(10, 0.51883733), (12, 0.43491545), (21, 0.046241388)]),\n",
       "  (79, [(6, 0.9999962)]),\n",
       "  (89, [(12, 0.9012864), (21, 0.09869896)])])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
