{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing PDFs \n",
    "\n",
    "Pull in all of the PDF files and create objects for the text inside each one. \n",
    "\n",
    "This also probably should include a spell check\n",
    "\n",
    "[One of the sources I am using for the topic modeling](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/)\n",
    "[This is a good post on Lemmatizing in python](https://www.machinelearningplus.com/nlp/lemmatization-examples-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "from glob import glob\n",
    "\n",
    "pdfs = glob('../pdfs/*.pdf') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../pdfs/Cruz - 2010 - Chapter Six. Expanding The View The Challenges Of.pdf',\n",
       " '../pdfs/Cruz - 2010 - Index.pdf',\n",
       " '../pdfs/Frederiks and Nagy - 2016 - Religion, migration, and identity methodological .pdf',\n",
       " '../pdfs/Cruz - 2010 - Introduction.pdf',\n",
       " '../pdfs/Cruz - 2010 - Chapter One. Geographies Of Domestication Mapping.pdf',\n",
       " '../pdfs/cruz2010.pdf',\n",
       " '../pdfs/Cruz - 2010 - Chapter Two. Frontiers Of Struggle Negotiating Fi.pdf',\n",
       " '../pdfs/Cruz - 2010 - Conclusion.pdf',\n",
       " '../pdfs/Cruz - 2010 - Chapter Four. Exploring Theological Markers Delor.pdf',\n",
       " '../pdfs/Cruz - 2010 - An intercultural theology of migration pilgrims i.pdf',\n",
       " \"../pdfs/Nguyen and Prior - 2014 - God's people on the move biblical and global pers.pdf\",\n",
       " '../pdfs/Cruz - 2010 - Chapter Three. Expanding The Boundaries Theologic.pdf',\n",
       " '../pdfs/Gods People on the Move 2.pdf',\n",
       " '../pdfs/Cruz - 2010 - Chapter Five. A Different Cartography Mapping The.pdf',\n",
       " '../pdfs/Izuzquiza - 2011 - Breaking bread notes for a political theology of .pdf',\n",
       " '../pdfs/Cruz - 2010 - Preliminary Material.pdf']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Texts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatizing and cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sgoodwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sgoodwin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS as STOPWORDS \n",
    "\n",
    "PUNCDIG_TRANSLATOR = str.maketrans('', '', string.punctuation+string.digits)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text):\n",
    "    clean_list = []\n",
    "    words = nltk.word_tokenize(text)\n",
    "    for w in words:\n",
    "        if w not in STOPWORDS:\n",
    "            w = w.translate(PUNCDIG_TRANSLATOR)\n",
    "            clean_list.append(lemmatizer.lemmatize(w))\n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['striped', 'bat', 'hanging', 'foot', 'best', '']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clean(\"The striped bats are hanging on their feet3 for best.\".lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = open(pdfs[0], 'rb')\n",
    "pdf_obj = PyPDF2.PdfFileReader(pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of pages: 35\n"
     ]
    }
   ],
   "source": [
    "print('No. of pages: {}'.format(pdf_obj.numPages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_extractor(pdf, corpus_list, text_list):\n",
    "    '''Extract the text of pdfs and return a dictionary with\n",
    "    the file name as a key, and the value being a list of the pages\n",
    "    and the containing texts\n",
    "    '''\n",
    "    pdf_file_obj = open(pdf, 'rb')\n",
    "    pdf_obj = PyPDF2.PdfFileReader(pdf_file_obj)\n",
    "    for pn in range(0,pdf_obj.numPages):\n",
    "        page = pdf_obj.getPage(pn)\n",
    "        text = page.extractText().lower()\n",
    "        cleaned_list = text_clean(text)\n",
    "        corpus_list.append(cleaned_list)\n",
    "        # corpus_list.append(page.extractText())\n",
    "        text_list.append((pdf, pn))\n",
    "        # if you want to create a dictionary\n",
    "        # text_dict.setdefault(pdf, []).append(page.extractText())\n",
    "    pdf_file_obj.close()\n",
    "    return corpus_list, text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
     ]
    }
   ],
   "source": [
    "corpus_list = []\n",
    "text_list = []\n",
    "\n",
    "for pdf in pdfs:\n",
    "    corpus_list, text_list = pdf_extractor(pdf, corpus_list, text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating LDA Model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora \n",
    "from gensim.models.ldamodel import LdaModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_topic_model(corpus_list):\n",
    "    corpus_dict = corpora.Dictionary(corpus_list)\n",
    "    corpus_dict.filter_extremes(no_below=100, no_above=0.5)\n",
    "    corpus = [corpus_dict.doc2bow(text) for text in corpus_list]\n",
    "    lda_model = LdaModel(corpus=corpus, \n",
    "                        id2word=corpus_dict, num_topics=25,\n",
    "                        random_state=100, update_every=1,\n",
    "                        chunksize=100, passes=50,\n",
    "                        alpha='symmetric', per_word_topics=True)\n",
    "    return lda_model, corpus, corpus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model, corpus, corpus_dict = prepare_topic_model(corpus_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      " [_prepare.py:257]\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "# The sort_topics=False makes the topic model numbers agree [+1] with the topic model from gensim\n",
    "# Gensim's topic numbers' are zero indexed, and the vis index is 1 indexed\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, corpus_dict, sort_topics=False, mds='mmds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the variable `vis` if you want to see the pyLDAvis model.\n",
    "# vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'PrelimTopicModel.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the Dominant Document For Each Topic \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a pandas DataFrame that orders all of the topics and shows the dominant topic for each document\n",
    "def format_topics_sent(ldamodel, corpus, texts):\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row[0], key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_topic', 'Perc_Contrib', 'Topic_Keywords']\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return sent_topics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dominant Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sent_gen(ldamodel, corpus, texts):\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        yield row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "genny = format_topics_sent_gen(lda_model, corpus, corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = next(genny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('”', 0.2966608),\n",
       " ('“', 0.2558419),\n",
       " ('’', 0.038733605),\n",
       " ('–', 0.03453399),\n",
       " ('vol', 0.03118087),\n",
       " ('e', 0.030572623),\n",
       " ('dhs', 0.028041013),\n",
       " ('s', 0.021423323),\n",
       " ('tulud', 0.015217608),\n",
       " ('cruz', 0.014499779)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.show_topic(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df = format_topics_sent(lda_model, corpus, text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpd_df = sent_topics_df.groupby('Dominant_topic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>migration, context, migrant, study, experience...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3923</td>\n",
       "      <td>immigrant, american, case, service, sense, gro...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.5300</td>\n",
       "      <td>new, ed, press, york, study, mission, book, ch...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7007</td>\n",
       "      <td>–, people, religion, dhs, order, come, life, e...</td>\n",
       "      <td>(../pdfs/Cruz - 2010 - Index.pdf, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.4219</td>\n",
       "      <td>’, s, god, experience, e, challenge, g, cruz, ...</td>\n",
       "      <td>(../pdfs/Cruz - 2010 - Chapter Four. Exploring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3031</td>\n",
       "      <td>economic, family, home, role, migration, er, t...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>nagy, dorottya, frederiks, martha, christian, ...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.4001</td>\n",
       "      <td>right, power, human, political, world, come, s...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>religion, identity, religious, culture, cultur...</td>\n",
       "      <td>(../pdfs/Cruz - 2010 - Chapter Six. Expanding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>struggle, filipino, philippine, eology, book, ...</td>\n",
       "      <td>(../pdfs/Cruz - 2010 - Preliminary Material.pd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>eology, e, feminist, cruz, tulud, g, woman, po...</td>\n",
       "      <td>(../pdfs/Cruz - 2010 - Preliminary Material.pd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>dhs, hong, kong, ’, filipino, hk, domestic, wo...</td>\n",
       "      <td>(../pdfs/Cruz - 2010 - Chapter One. Geographie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.4642</td>\n",
       "      <td>church, christian, role, context, american, ti...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.8413</td>\n",
       "      <td>”, “, ’, –, vol, e, dhs, s, tulud, cruz</td>\n",
       "      <td>(../pdfs/Cruz - 2010 - Chapter One. Geographie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5705</td>\n",
       "      <td>migrant, worker, country, domestic, work, soci...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.4450</td>\n",
       "      <td>people, place, fact, example, make, situation,...</td>\n",
       "      <td>(../pdfs/Izuzquiza - 2011 - Breaking bread not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>work, study, form, relation, place, question, ...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.6731</td>\n",
       "      <td>life, god, word, people, way, mean, reality, t...</td>\n",
       "      <td>(../pdfs/Izuzquiza - 2011 - Breaking bread not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>woman, ’, s, experience, particularly, oppress...</td>\n",
       "      <td>(../pdfs/Cruz - 2010 - Chapter Four. Exploring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.5590</td>\n",
       "      <td>community, group, religious, migrant, faith, c...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.4630</td>\n",
       "      <td>theology, theological, context, way, new, ques...</td>\n",
       "      <td>(../pdfs/Frederiks and Nagy - 2016 - Religion,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.4607</td>\n",
       "      <td>social, cultural, political, society, reality,...</td>\n",
       "      <td>(../pdfs/Izuzquiza - 2011 - Breaking bread not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24.0</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>d, c, come, dhs, life, order, case, like, hk, ...</td>\n",
       "      <td>(../pdfs/Gods People on the Move 2.pdf, 14)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic_Num  Topic_Perc_Contrib  \\\n",
       "0         0.0              0.5008   \n",
       "1         1.0              0.3923   \n",
       "2         2.0              0.5300   \n",
       "3         3.0              0.7007   \n",
       "4         4.0              0.4219   \n",
       "5         5.0              0.3031   \n",
       "6         6.0              0.8080   \n",
       "7         7.0              0.4001   \n",
       "8         8.0              0.4924   \n",
       "9         9.0              0.3283   \n",
       "10       10.0              0.8040   \n",
       "11       11.0              0.8343   \n",
       "12       12.0              0.4642   \n",
       "13       13.0              0.8413   \n",
       "14       14.0              0.5705   \n",
       "15       15.0              0.4450   \n",
       "16       17.0              0.4085   \n",
       "17       18.0              0.6731   \n",
       "18       19.0              0.5663   \n",
       "19       20.0              0.5590   \n",
       "20       21.0              0.4630   \n",
       "21       22.0              0.4607   \n",
       "22       24.0              0.9262   \n",
       "\n",
       "                                             Keywords  \\\n",
       "0   migration, context, migrant, study, experience...   \n",
       "1   immigrant, american, case, service, sense, gro...   \n",
       "2   new, ed, press, york, study, mission, book, ch...   \n",
       "3   –, people, religion, dhs, order, come, life, e...   \n",
       "4   ’, s, god, experience, e, challenge, g, cruz, ...   \n",
       "5   economic, family, home, role, migration, er, t...   \n",
       "6   nagy, dorottya, frederiks, martha, christian, ...   \n",
       "7   right, power, human, political, world, come, s...   \n",
       "8   religion, identity, religious, culture, cultur...   \n",
       "9   struggle, filipino, philippine, eology, book, ...   \n",
       "10  eology, e, feminist, cruz, tulud, g, woman, po...   \n",
       "11  dhs, hong, kong, ’, filipino, hk, domestic, wo...   \n",
       "12  church, christian, role, context, american, ti...   \n",
       "13            ”, “, ’, –, vol, e, dhs, s, tulud, cruz   \n",
       "14  migrant, worker, country, domestic, work, soci...   \n",
       "15  people, place, fact, example, make, situation,...   \n",
       "16  work, study, form, relation, place, question, ...   \n",
       "17  life, god, word, people, way, mean, reality, t...   \n",
       "18  woman, ’, s, experience, particularly, oppress...   \n",
       "19  community, group, religious, migrant, faith, c...   \n",
       "20  theology, theological, context, way, new, ques...   \n",
       "21  social, cultural, political, society, reality,...   \n",
       "22  d, c, come, dhs, life, order, case, like, hk, ...   \n",
       "\n",
       "                                                 Text  \n",
       "0   (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "1   (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "2   (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "3                (../pdfs/Cruz - 2010 - Index.pdf, 2)  \n",
       "4   (../pdfs/Cruz - 2010 - Chapter Four. Exploring...  \n",
       "5   (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "6   (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "7   (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "8   (../pdfs/Cruz - 2010 - Chapter Six. Expanding ...  \n",
       "9   (../pdfs/Cruz - 2010 - Preliminary Material.pd...  \n",
       "10  (../pdfs/Cruz - 2010 - Preliminary Material.pd...  \n",
       "11  (../pdfs/Cruz - 2010 - Chapter One. Geographie...  \n",
       "12  (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "13  (../pdfs/Cruz - 2010 - Chapter One. Geographie...  \n",
       "14  (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "15  (../pdfs/Izuzquiza - 2011 - Breaking bread not...  \n",
       "16  (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "17  (../pdfs/Izuzquiza - 2011 - Breaking bread not...  \n",
       "18  (../pdfs/Cruz - 2010 - Chapter Four. Exploring...  \n",
       "19  (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "20  (../pdfs/Frederiks and Nagy - 2016 - Religion,...  \n",
       "21  (../pdfs/Izuzquiza - 2011 - Breaking bread not...  \n",
       "22        (../pdfs/Gods People on the Move 2.pdf, 14)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This code creates a pandas DataFrame that shows which document is exemplified by which topic\n",
    "sent_topics_df = pd.DataFrame()\n",
    "\n",
    "for i, grp in grpd_df:\n",
    "    sent_topics_df = pd.concat([sent_topics_df, grp.sort_values(['Perc_Contrib'], ascending=[0]).head(1)], axis=0)\n",
    "\n",
    "sent_topics_df.reset_index(drop=True, inplace=True)\n",
    "sent_topics_df.columns = ['Topic_Num', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "sent_topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../pdfs/Frederiks and Nagy - 2016 - Religion, migration, and identity methodological .pdf',\n",
       " 63)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_df.iloc[0]['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('migration', 0.5920657),\n",
       " ('context', 0.12714523),\n",
       " ('migrant', 0.0677818),\n",
       " ('study', 0.05909739),\n",
       " ('experience', 0.037804633),\n",
       " ('tion', 0.024900865),\n",
       " ('community', 0.021318907),\n",
       " ('challenge', 0.017123718),\n",
       " ('human', 0.014246021),\n",
       " ('culture', 0.012124161)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.show_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
